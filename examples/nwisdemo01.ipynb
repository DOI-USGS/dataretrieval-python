{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National trends in peak annual streamflow\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates a slightly more advanced application of data_retrieval.nwis to collect  using a national dataset of historical peak annual streamflow measurements. The objective is to use a regression of peak annual streamflow and time to identify any trends. But, not for a singile station,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before we begin any analysis, we'll need to setup our environment by importing any modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:45.847815Z",
     "iopub.status.busy": "2023-01-08T03:57:45.847241Z",
     "iopub.status.idle": "2023-01-08T03:57:46.562453Z",
     "shell.execute_reply": "2023-01-08T03:57:46.561559Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from dataretrieval import nwis, utils, codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "Recall that the basic way to download data from NWIS is through through the `nwis.get_record()` function, which returns a user-specified record as a `pandas` dataframe. The `nwis.get_record()` function is really a facade of sorts, that allows the user to download data from various NWIS services through a consistant interface. To get started, we require a few simple parameters: a list of site numbers or states codes, a service, and a start date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:46.566623Z",
     "iopub.status.busy": "2023-01-08T03:57:46.566261Z",
     "iopub.status.idle": "2023-01-08T03:57:47.202714Z",
     "shell.execute_reply": "2023-01-08T03:57:47.201914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>peak_tm</th>\n",
       "      <th>peak_va</th>\n",
       "      <th>peak_cd</th>\n",
       "      <th>gage_ht</th>\n",
       "      <th>gage_ht_cd</th>\n",
       "      <th>year_last_pk</th>\n",
       "      <th>ag_dt</th>\n",
       "      <th>ag_tm</th>\n",
       "      <th>ag_gage_ht</th>\n",
       "      <th>ag_gage_ht_cd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-04-20 00:00:00+00:00</th>\n",
       "      <td>USGS</td>\n",
       "      <td>03339000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16300</td>\n",
       "      <td>5</td>\n",
       "      <td>19.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-02-05 00:00:00+00:00</th>\n",
       "      <td>USGS</td>\n",
       "      <td>03339000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8910</td>\n",
       "      <td>5</td>\n",
       "      <td>13.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972-04-22 00:00:00+00:00</th>\n",
       "      <td>USGS</td>\n",
       "      <td>03339000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9240</td>\n",
       "      <td>5</td>\n",
       "      <td>13.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973-04-23 00:00:00+00:00</th>\n",
       "      <td>USGS</td>\n",
       "      <td>03339000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16600</td>\n",
       "      <td>5</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-06-23 00:00:00+00:00</th>\n",
       "      <td>USGS</td>\n",
       "      <td>03339000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19500</td>\n",
       "      <td>5</td>\n",
       "      <td>21.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          agency_cd   site_no peak_tm  peak_va peak_cd  \\\n",
       "datetime                                                                 \n",
       "1970-04-20 00:00:00+00:00      USGS  03339000     NaN    16300       5   \n",
       "1971-02-05 00:00:00+00:00      USGS  03339000     NaN     8910       5   \n",
       "1972-04-22 00:00:00+00:00      USGS  03339000     NaN     9240       5   \n",
       "1973-04-23 00:00:00+00:00      USGS  03339000     NaN    16600       5   \n",
       "1974-06-23 00:00:00+00:00      USGS  03339000     NaN    19500       5   \n",
       "\n",
       "                           gage_ht  gage_ht_cd  year_last_pk ag_dt  ag_tm  \\\n",
       "datetime                                                                    \n",
       "1970-04-20 00:00:00+00:00    19.80         NaN           NaN   NaN    NaN   \n",
       "1971-02-05 00:00:00+00:00    13.61         NaN           NaN   NaN    NaN   \n",
       "1972-04-22 00:00:00+00:00    13.94         NaN           NaN   NaN    NaN   \n",
       "1973-04-23 00:00:00+00:00    20.00         NaN           NaN   NaN    NaN   \n",
       "1974-06-23 00:00:00+00:00    21.70         NaN           NaN   NaN    NaN   \n",
       "\n",
       "                           ag_gage_ht  ag_gage_ht_cd  \n",
       "datetime                                              \n",
       "1970-04-20 00:00:00+00:00         NaN            NaN  \n",
       "1971-02-05 00:00:00+00:00         NaN            NaN  \n",
       "1972-04-22 00:00:00+00:00         NaN            NaN  \n",
       "1973-04-23 00:00:00+00:00         NaN            NaN  \n",
       "1974-06-23 00:00:00+00:00         NaN            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download annual peaks from a single site\n",
    "df = nwis.get_record(sites='03339000', service='peaks', start='1970-01-01')\n",
    "df.head()\n",
    "\n",
    "# alternatively information for the entire state of illiois can be downloaded using\n",
    "#df = nwis.get_record(state_cd='il', service='peaks', start='1970-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the fields are empty, but no matter. All we require are date (`datetime`), site number (`site_no`), and peak streamflow (`peak_va`).\n",
    "\n",
    "Note that when multiple sites are specified, `nwis.get_record()` will combine `datetime` and `site_no` fields to create a multi-index dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the regression\n",
    "Next we'll define a function that applies ordinary least squares on peak discharge and time.\n",
    "After grouping the dataset by `site_no`, we will apply the regression on a per-site basis. The results from each site, will be returned as a row that includes the slope, y-intercept, r$^2$, p value, and standard error of the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:47.207208Z",
     "iopub.status.busy": "2023-01-08T03:57:47.206631Z",
     "iopub.status.idle": "2023-01-08T03:57:47.214613Z",
     "shell.execute_reply": "2023-01-08T03:57:47.213754Z"
    }
   },
   "outputs": [],
   "source": [
    "def peak_trend_regression(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #convert datetimes to days for regression\n",
    "    peak_date = df.index\n",
    "    peak_date = pd.to_datetime(df.index.get_level_values(1))\n",
    "    df['peak_d'] = (peak_date - peak_date.min()) / np.timedelta64(1,'D')\n",
    "    #df['peak_d'] = (df['peak_dt'] - df['peak_dt'].min())  / np.timedelta64(1,'D')\n",
    "    \n",
    "    #normalize the peak discharge values\n",
    "    df['peak_va'] = (df['peak_va'] - df['peak_va'].mean())/df['peak_va'].std()\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(df['peak_d'], df['peak_va'])\n",
    "    \n",
    "    #df_out = pd.DataFrame({'slope':slope,'intercept':intercept,'p_value':p_value},index=df['site_no'].iloc[0])\n",
    "    \n",
    "    #return df_out\n",
    "    return pd.Series({'slope':slope,'intercept':intercept,'p_value': p_value,'std_error':std_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:47.219281Z",
     "iopub.status.busy": "2023-01-08T03:57:47.219035Z",
     "iopub.status.idle": "2023-01-08T03:57:47.225620Z",
     "shell.execute_reply": "2023-01-08T03:57:47.224423Z"
    }
   },
   "outputs": [],
   "source": [
    "def peak_trend_analysis(states, start_date):\n",
    "    \"\"\"\n",
    "    states : list\n",
    "        a list containing the two-letter codes for each state to include in the \n",
    "        analysis.\n",
    "    \n",
    "    start_date : string\n",
    "        the date to use a the beginning of the analysis.\n",
    "    \"\"\"\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    for state in states:\n",
    "        # download annual peak discharge records\n",
    "        df = nwis.get_record(state_cd=state, start=start_date, service='peaks')\n",
    "        # group the data by site and apply our regression\n",
    "        temp = df.groupby('site_no').apply(peak_trend_regression).dropna()\n",
    "        # drop any insignificant results\n",
    "        temp = temp[temp['p_value']<0.05]\n",
    "        \n",
    "        # now download metadata for each site, which we'll use later to plot the sites\n",
    "        # on a map\n",
    "        site_df = nwis.get_record(sites=temp.index, service='site')\n",
    "        \n",
    "        if final_df.empty:\n",
    "            final_df = pd.merge(site_df, temp, right_index=True, left_on='site_no')\n",
    "            \n",
    "        else:\n",
    "            final_df = final_df.append( pd.merge(site_df, temp, right_index=True, left_on='site_no') )\n",
    "            \n",
    "    return final_df\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the analysis for all states since 1970, one would only need to uncomment and run the following lines. However, pulling all that data from NWIS takes time and puts and could put a burden on resoures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:47.229411Z",
     "iopub.status.busy": "2023-01-08T03:57:47.229156Z",
     "iopub.status.idle": "2023-01-08T03:57:47.232406Z",
     "shell.execute_reply": "2023-01-08T03:57:47.231564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Warning these lines will download a large dataset from the web and\n",
    "# will take few minutes to run.\n",
    "\n",
    "#start = '1970-01-01'\n",
    "#states = codes.state_codes\n",
    "#final_df = peak_trend_analysis(states=states, start_date=start)\n",
    "#final_df.to_csv('datasets/peak_discharge_trends.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, lets quickly load some predownloaded data, which I generated using the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:47.235675Z",
     "iopub.status.busy": "2023-01-08T03:57:47.235428Z",
     "iopub.status.idle": "2023-01-08T03:57:47.272281Z",
     "shell.execute_reply": "2023-01-08T03:57:47.271465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>station_nm</th>\n",
       "      <th>site_tp_cd</th>\n",
       "      <th>dec_lat_va</th>\n",
       "      <th>dec_long_va</th>\n",
       "      <th>coord_acy_cd</th>\n",
       "      <th>dec_coord_datum_cd</th>\n",
       "      <th>alt_va</th>\n",
       "      <th>alt_acy_va</th>\n",
       "      <th>alt_datum_cd</th>\n",
       "      <th>huc_cd</th>\n",
       "      <th>intercept</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope</th>\n",
       "      <th>std_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>USGS</td>\n",
       "      <td>2343275</td>\n",
       "      <td>ABBIE CREEK NEAR ABBEVILLE AL</td>\n",
       "      <td>ST</td>\n",
       "      <td>31.561836</td>\n",
       "      <td>-85.204932</td>\n",
       "      <td>U</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3130004.0</td>\n",
       "      <td>-0.641911</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>USGS</td>\n",
       "      <td>2360275</td>\n",
       "      <td>JUDY CREEK NEAR OZARK AL</td>\n",
       "      <td>ST</td>\n",
       "      <td>31.463224</td>\n",
       "      <td>-85.572159</td>\n",
       "      <td>U</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3140201.0</td>\n",
       "      <td>-0.702569</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USGS</td>\n",
       "      <td>2360500</td>\n",
       "      <td>EAST FORK CHOCTAWHATCHEE R NEAR MIDLAND CITY AL</td>\n",
       "      <td>ST</td>\n",
       "      <td>31.373227</td>\n",
       "      <td>-85.477158</td>\n",
       "      <td>U</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>179.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NGVD29</td>\n",
       "      <td>3140201.0</td>\n",
       "      <td>-1.138552</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>USGS</td>\n",
       "      <td>2367400</td>\n",
       "      <td>YELLOW RIVER NR SANFORD, ALA</td>\n",
       "      <td>ST</td>\n",
       "      <td>31.317391</td>\n",
       "      <td>-86.355788</td>\n",
       "      <td>U</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3140103.0</td>\n",
       "      <td>-0.611310</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>USGS</td>\n",
       "      <td>2367500</td>\n",
       "      <td>LIGHTWOOD KNOT CREEK AT BABBIE AL</td>\n",
       "      <td>ST</td>\n",
       "      <td>31.270725</td>\n",
       "      <td>-86.313564</td>\n",
       "      <td>U</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NGVD29</td>\n",
       "      <td>3140103.0</td>\n",
       "      <td>-0.705676</td>\n",
       "      <td>0.015231</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 agency_cd  site_no  \\\n",
       "0           0      USGS  2343275   \n",
       "1           1      USGS  2360275   \n",
       "2           2      USGS  2360500   \n",
       "3           3      USGS  2367400   \n",
       "4           4      USGS  2367500   \n",
       "\n",
       "                                        station_nm site_tp_cd  dec_lat_va  \\\n",
       "0                    ABBIE CREEK NEAR ABBEVILLE AL         ST   31.561836   \n",
       "1                         JUDY CREEK NEAR OZARK AL         ST   31.463224   \n",
       "2  EAST FORK CHOCTAWHATCHEE R NEAR MIDLAND CITY AL         ST   31.373227   \n",
       "3                     YELLOW RIVER NR SANFORD, ALA         ST   31.317391   \n",
       "4                LIGHTWOOD KNOT CREEK AT BABBIE AL         ST   31.270725   \n",
       "\n",
       "   dec_long_va coord_acy_cd dec_coord_datum_cd  alt_va  alt_acy_va  \\\n",
       "0   -85.204932            U              NAD83     NaN         NaN   \n",
       "1   -85.572159            U              NAD83     NaN         NaN   \n",
       "2   -85.477158            U              NAD83   179.1        0.01   \n",
       "3   -86.355788            U              NAD83     NaN         NaN   \n",
       "4   -86.313564            U              NAD83   185.0        0.01   \n",
       "\n",
       "  alt_datum_cd     huc_cd  intercept   p_value     slope  std_error  \n",
       "0          NaN  3130004.0  -0.641911  0.015899  0.000231   0.000065  \n",
       "1          NaN  3140201.0  -0.702569  0.004652  0.000269   0.000069  \n",
       "2       NGVD29  3140201.0  -1.138552  0.007698  0.000211   0.000003  \n",
       "3          NaN  3140103.0  -0.611310  0.015836  0.000511   0.000013  \n",
       "4       NGVD29  3140103.0  -0.705676  0.015231  0.000210   0.000052  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv('datasets/peak_discharge_trends.csv')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the data has been transformed. In addition to statistics about the peak streamflow trends, we've also used the NWIS site service to add latitude and longtitude information for each station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the results\n",
    "Finally we'll use `basemap` and `matplotlib`, along with the location information from NWIS, to plot the results on a map (shown below). Stations with increasing peak annual discharge are shown in red; whereas, stations with decreasing peaks are blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-08T03:57:47.276291Z",
     "iopub.status.busy": "2023-01-08T03:57:47.275965Z",
     "iopub.status.idle": "2023-01-08T03:57:47.280407Z",
     "shell.execute_reply": "2023-01-08T03:57:47.279638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Currently commented out as there isn't an easy way to install mpl_toolkits \n",
    "# on a remote machine without spinning up a full geospatial stack.\n",
    "\n",
    "# from mpl_toolkits.basemap import Basemap, cm\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(num=None, figsize=(10, 6) )\n",
    "\n",
    "# # setup a basemap covering the contiguous United States\n",
    "# m = Basemap(width=5500000, height=4000000, resolution='l',\n",
    "#             projection='aea', lat_1=36., lat_2=44, lon_0=-100, lat_0=40)\n",
    "\n",
    "\n",
    "# # add coastlines\n",
    "# m.drawcoastlines(linewidth=0.5)\n",
    "\n",
    "# # add parallels and meridians.\n",
    "# m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])\n",
    "# m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])\n",
    "\n",
    "# # add boundaries and rivers\n",
    "# m.drawcountries(linewidth=1, linestyle='solid', color='k' ) \n",
    "# m.drawstates(linewidth=0.5, linestyle='solid', color='k')\n",
    "# m.drawrivers(linewidth=0.5, linestyle='solid', color='cornflowerblue')\n",
    "\n",
    "\n",
    "# increasing = final_df[final_df['slope'] > 0]\n",
    "# decreasing = final_df[final_df['slope'] < 0]\n",
    "\n",
    "# #x,y = m(lons, lats)\n",
    "\n",
    "# # categorical plots get a little  ugly in basemap\n",
    "# m.scatter(increasing['dec_long_va'].tolist(), \n",
    "#           increasing['dec_lat_va'].tolist(), \n",
    "#           label='increasing', s=2, color='red',\n",
    "#           latlon=True)\n",
    "\n",
    "# m.scatter(decreasing['dec_long_va'].tolist(), \n",
    "#           decreasing['dec_lat_va'].tolist(), \n",
    "#           label='increasing', s=2, color='blue',\n",
    "#           latlon=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2da9d245c691c2995f0592d1f809d130e15c1d01d60d03d4ca8d56ea51bb4095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
