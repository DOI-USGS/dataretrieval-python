{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a21fd49-09b0-4e09-870c-c9694d913565",
   "metadata": {},
   "source": [
    "# Fill Discharge Data\n",
    "\n",
    "The goal of this notebook is to extend the `nwis.get_dv()` for discharge data to search for nearby sites and use their discharge data to fill any missing data in the original site.\n",
    "\n",
    "The general steps for this approach are:\n",
    "\n",
    "1) Given a site, as well as neighborhood search parameters, search for sites on the stream's main stem for \"neighboring\" sites\n",
    "    - The neighborhood search will assume the drainage area to the site is a circle and the radius of that circle is the distance to search within. This radius can then be scaled by some scale factor.\n",
    "    - \"Neighboring\" sites can be both upstream or downstream.\n",
    "2) Apply a filter to the \"neighboring\" sites, limiting to sites with discharge. Also, drop any sites on the main stem that somehow have drastically lower drainage areas.\n",
    "3) Pull discharge data for each of the filtered \"neighboring\" sites.\n",
    "4) Limit this discharge data to the dates with missing data in the original site.\n",
    "5) Scale the discharge data associated with each \"neighboring\" site by the inverse of the fraction of its drainage area to the drainage area of the original site.\n",
    "6) Fill the missing data in the original site preferentially using the \"neighboring\" site with data at that time and an inverse drainage area fraction closest to 1 (i.e., use the site with the drainage area most similar to the original site).\n",
    "\n",
    "> Note: This method could be expanded to take tributaries as well (vs. just main stem) and add their discharge with the upstream main stem \"neighboring\" sites for more accurate discharge compared to just drainage area scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f78869-0e4e-475b-bd95-d0ca86064de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataretrieval import nwis, nldi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sciencebasepy import SbSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29edeb0-d078-4da4-b27c-dfd423006510",
   "metadata": {},
   "source": [
    "These are the inputs required for the method.\n",
    "\n",
    "1) site number\n",
    "2) start date of the discharge time series\n",
    "3) end data of the discharge time series\n",
    "4) factor to scale the drainage area radius for neighbor searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22764220-a358-4325-a2aa-410ec1d786ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_no = '05586100'\n",
    "start_date = '1900-01-01'\n",
    "end_date = '2024-08-01'\n",
    "neighborhood_scale = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b254a-2e32-4c11-8975-79f28d6eeaad",
   "metadata": {},
   "source": [
    "Get the data for the original site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f399b01-57d9-4f48-bab4-9b1086db512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the discharge data for the site\n",
    "df, _ = nwis.get_dv(sites=site_no, start=start_date, end=end_date, parameterCd='00060')\n",
    "# Replace missing data (-999999) with NaN\n",
    "df['00060_Mean'] = df['00060_Mean'].replace(-999999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09ba90-84e1-4d7d-aae2-912c43c3acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for fun\n",
    "_ = df['00060_Mean'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7a510-0b93-41a9-a8b4-539702a3beae",
   "metadata": {},
   "source": [
    "Get the site drainage area info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab371f-7c99-4b52-8bd5-9362e58b90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get you initial distance from the drainage area\n",
    "df_nwis, _ = nwis.get_info(sites=site_no)\n",
    "\n",
    "# To get a search radius for checking for neighboring sites,\n",
    "# use the drainage area, assuming it is a circular area and\n",
    "# use its radius as the search distance\n",
    "# Note: the NWIS drainage area is in mi2\n",
    "drainage_area = df_nwis['drain_area_va'][0]\n",
    "\n",
    "# Check if the drainage area is missing. If it is,\n",
    "# use the NLDI to get the area from the drainage basin.\n",
    "# While this could be done regardless and is more accurate,\n",
    "# perfect accuracy is not needed and it is not as fast.\n",
    "# Note: the EPSG:5070 projection of the NLDI basin is in m.\n",
    "m_per_mi = 1609.344\n",
    "if np.isnan(drainage_area):\n",
    "    basin = nldi.get_basin(feature_source=\"WQP\",\n",
    "                           feature_id=f\"USGS-{site_no}\")\n",
    "    # Update crs\n",
    "    basin = basin.set_crs('EPSG:4326').to_crs('EPSG:5070')\n",
    "    # Get area. Convert to mi2\n",
    "    drainage_area = basin.area[0] / (m_per_mi ** 2)\n",
    "\n",
    "# Calculate neighbor search distance assuming circular drainage area\n",
    "neighbor_distance = np.sqrt(drainage_area / np.pi) * neighborhood_scale\n",
    "print(f'Drainage area [mi2]: {drainage_area}')\n",
    "print(f'Neighbor search distance [mi]: {neighbor_distance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabaaad7-432b-4722-91aa-737b99e7e358",
   "metadata": {},
   "source": [
    "Get the neighboring sites from the NLDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f997e79-1452-4623-b163-5ccb3a307675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NLDI to search upstream and downsteam for sites\n",
    "# Note: NLDI features distance is in km\n",
    "nldi_distance = neighbor_distance * m_per_mi / 1e3\n",
    "\n",
    "# Search upstream and downstream on the main stem\n",
    "gdf_features_up = nldi.get_features(feature_source=\"WQP\", \n",
    "                                    feature_id=f\"USGS-{site_no}\",\n",
    "                                    navigation_mode=\"UM\",\n",
    "                                    distance=nldi_distance,\n",
    "                                    data_source=\"nwissite\")\n",
    "gdf_features_down = nldi.get_features(feature_source=\"WQP\",\n",
    "                                      feature_id=f\"USGS-{site_no}\",\n",
    "                                      navigation_mode=\"DM\",\n",
    "                                      distance=nldi_distance,\n",
    "                                      data_source=\"nwissite\")\n",
    "neighbor_sites = pd.concat([gdf_features_up['identifier'],\n",
    "                            gdf_features_down['identifier']],\n",
    "                           ignore_index=True)\n",
    "\n",
    "# Drop the original site itself as it will be returned\n",
    "neighbor_sites = neighbor_sites[neighbor_sites != f\"USGS-{site_no}\"]\n",
    "neighbor_sites = neighbor_sites.str.strip('USGS-')\n",
    "neighbor_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb05ef-97a1-41e3-921c-b8af2a61c7e8",
   "metadata": {},
   "source": [
    "Limit selected sites to only those with discharge measurements and those that have greater than 10% of the original site's drainage area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd39e6e-3df1-49b2-a154-e3db3ed30f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the info on the sites that have discharge measurements\n",
    "df_neighbors, _ = nwis.get_info(sites=neighbor_sites.to_list(), parameterCd='00060')\n",
    "# Keep those that are greater than 10% of the original drainage area\n",
    "df_neighbors = df_neighbors[(df_neighbors['drain_area_va'] / drainage_area) > 0.1]\n",
    "df_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02064168-25a3-40cd-90a5-e6a44509ba21",
   "metadata": {},
   "source": [
    "Pull discharge data for each of the filtered \"neighboring\" sites.\n",
    "\n",
    "We could also pull each site individually. By pulling individually, we would only pull the neighboring sites and fill missing data as needed, until our time range has been fully filled. This could save some data pulling if we have a lot of sites and only some missing data. However, it is not possible to know what sites have data on what days. Therefore, we can just pull it all and once and filter from there. This limits the number of NWIS API calls and should be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95151a8f-829c-4b75-8d41-03ebfabbd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the discharge for the neighboring sites\n",
    "neighbor_discharge, _ = nwis.get_dv(sites=df_neighbors['site_no'].to_list(), start=start_date, end=end_date, parameterCd='00060')\n",
    "# Add multi-index to allow for easy xarray conversion\n",
    "if 'site_no' in neighbor_discharge.columns:\n",
    "    neighbor_discharge = neighbor_discharge.set_index(['site_no', neighbor_discharge.index])\n",
    "neighbor_discharge = neighbor_discharge.to_xarray()\n",
    "neighbor_discharge['datetime'] = pd.DatetimeIndex(neighbor_discharge['datetime'].values)\n",
    "\n",
    "# Get the dates with missing values\n",
    "missing = df[df['00060_Mean'].isna()].index.values\n",
    "# Limit the missing dates to only be within the date range of the fill values\n",
    "missing = missing[(missing >= neighbor_discharge['datetime'].min().values) \n",
    "                  & (missing <= neighbor_discharge['datetime'].max().values)]\n",
    "\n",
    "# Limit this discharge data to the dates with missing data in the original site.\n",
    "neighbor_discharge = neighbor_discharge.sel(datetime=missing)\n",
    "neighbor_discharge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7fa6e-3b36-4f68-9cfc-e60b684a3b63",
   "metadata": {},
   "source": [
    "Scale the discharge data associated with each \"neighboring\" site by the inverse of the fraction of its drainage area to the drainage area of the original site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a119d3fc-4314-4a72-ad05-56786ba6dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the drainage fractions\n",
    "neighbor_discharge['drainage_frac'] = xr.DataArray(drainage_area / df_neighbors.set_index('site_no')['drain_area_va'])\n",
    "# Scale the discharge\n",
    "neighbor_discharge['00060_Mean'] *= neighbor_discharge['drainage_frac']\n",
    "neighbor_discharge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce509f94-4331-4ec5-8169-d3e85b5f5b71",
   "metadata": {},
   "source": [
    "Fill the missing data in the original site preferentially using the \"neighboring\" site with data at that time and an inverse drainage area fraction closest to 1 (i.e., use the site with the drainage area most similar to the original site)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d6f24-d08b-4de0-aca0-3ff29b535f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_discharge['frac_diff'] = np.abs(neighbor_discharge['drainage_frac'] - 1)\n",
    "neighbor_discharge = neighbor_discharge.sortby('frac_diff')\n",
    "\n",
    "for neighbor_site_no in neighbor_discharge['site_no'].values:\n",
    "    fill_data = neighbor_discharge.sel(site_no=neighbor_site_no)['00060_Mean'].to_dataframe().drop(columns='site_no')\n",
    "    fill_data.index = fill_data.index.tz_localize('utc')\n",
    "    df = df.fillna(fill_data)\n",
    "\n",
    "    # End early if we fill all missing data\n",
    "    if df['00060_Mean'].isna().sum() == 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
